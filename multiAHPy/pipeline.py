from __future__ import annotations
from typing import List, Dict, Any, Literal, Tuple
import numpy as np
from .model import Hierarchy, Node
from .types import NumericType
from .aggregation import aggregate_matrices

# Define the two main workflows
WorkflowType = Literal["ranking", "scoring"]

class Workflow:
    """
    A pipeline for executing a complete AHP analysis from data to results.

    This class encapsulates the entire sequence of operations for a specific AHP
    workflow, ensuring that steps are not missed and that the process is
    reproducible. It's inspired by scikit-learn's Pipeline object.

    Workflow Steps:
    1. Initialize the workflow with a hierarchy structure and a full method recipe.
    2. Provide the necessary data (expert matrices or performance scores).
    3. Run the pipeline to get the final results.

    Example:
        # 1. Define hierarchy and recipe
        root_node = ...
        recipe = suggester.get_model_recipe(...)

        # 2. Create the pipeline
        pipeline = AHPWorkflow(
            root_node=root_node,
            workflow_type="ranking", # or "scoring"
            recipe=recipe
        )

        # 3. Fit it with data and get results
        expert_matrices = {'criteria': [...], 'leaf1': [...]}
        pipeline.run(expert_matrices)

        print(pipeline.rankings)
    """

    def __init__(
        self,
        root_node: Node,
        workflow_type: WorkflowType,
        recipe: Dict[str, Any],
        alternatives: List[str]
    ):
        """
        Initializes the AHP Workflow Pipeline.

        Args:
            root_node: The root node of the AHP hierarchy structure.
            workflow_type: The type of analysis to perform.
                           - 'ranking': Classic AHP to rank alternatives via pairwise comparison.
                           - 'scoring': AHP as a weighting engine to score alternatives on performance data.
            recipe: A dictionary of methods, typically generated by `ahp.suggester`.
                    Must contain 'number_type', 'aggregation_method', 'weight_derivation_method'.
            alternatives: A list of the names of the alternatives.
        """
        if workflow_type not in ["ranking", "scoring"]:
            raise ValueError("workflow_type must be either 'ranking' or 'scoring'.")

        self.workflow_type = workflow_type
        self.recipe = recipe
        self.rankings: List[Tuple[str, float]] | None = None
        self.consistency_report: Dict[str, Any] | None = None

        # Internally, the pipeline manages its own Hierarchy model
        self.model = Hierarchy(root_node, number_type=recipe['number_type'])
        for alt_name in alternatives:
            self.model.add_alternative(alt_name)

    def run(
        self,
        expert_matrices: Dict[str, List[np.ndarray]] | None = None,
        performance_scores: Dict[str, Dict[str, float]] | None = None,
        expert_weights: List[float] | None = None
    ) -> 'Workflow':
        """
        Executes the entire AHP pipeline with the provided data.

        Args:
            expert_matrices: A dictionary mapping a node ID to a list of expert
                             comparison matrices. Required for 'ranking' workflow.
                             Example: {'Goal': [m1, m2], 'Price': [m1, m2]}
            performance_scores: A dictionary mapping an alternative name to its
                                performance scores. Required for 'scoring' workflow.
                                Example: {'Car A': {'Price': 0.9, 'Safety': 0.6}}
            expert_weights: Optional list of weights for the experts for aggregation.

        Returns:
            The fitted pipeline object, with results stored in its attributes.
        """
        print(f"--- Running AHP Workflow: '{self.workflow_type}' ---")

        # --- Step 1: Aggregate Matrices (if multiple experts) ---
        aggregated_data = {}
        aggregation_method = self.recipe.get('aggregation_method', 'geometric')

        if expert_matrices:
            for node_id, matrices in expert_matrices.items():
                if len(matrices) > 1:
                    print(f"  - Aggregating {len(matrices)} matrices for node '{node_id}' using '{aggregation_method}'...")
                    agg_matrix = aggregate_matrices(
                        matrices,
                        method=aggregation_method,
                        expert_weights=expert_weights,
                        number_type=self.model.number_type
                    )
                    aggregated_data[node_id] = agg_matrix
                elif matrices:
                    aggregated_data[node_id] = matrices[0]

        # --- Step 2: Set data on the model ---
        for node_id, matrix in aggregated_data.items():
            node = self.model._find_node(node_id)
            if not node:
                raise ValueError(f"Node '{node_id}' from your data was not found in the hierarchy.")

            if node.is_leaf:
                self.model.set_alternative_matrix(node_id, matrix)
            else:
                self.model.set_comparison_matrix(node_id, matrix)

        # --- Step 3: Run the core AHP calculations in the correct order ---

        # 3.1: Calculate criteria weights (required for both workflows)
        self.model.calculate_weights(method=self.recipe['weight_derivation_method'])

        # 3.2: Calculate final scores based on the workflow type
        if self.workflow_type == 'ranking':
            if not expert_matrices:
                raise ValueError("The 'ranking' workflow requires the 'expert_matrices' argument.")
            self.model.rank_alternatives_by_comparison(derivation_method=self.recipe['weight_derivation_method'])

        elif self.workflow_type == 'scoring':
            if not performance_scores:
                raise ValueError("The 'scoring' workflow requires the 'performance_scores' argument.")
            # Set the performance scores on the alternatives
            for alt_name, scores in performance_scores.items():
                alt_obj = self.model.get_alternative(alt_name)
                for leaf_id, score in scores.items():
                    alt_obj.set_performance_score(leaf_id, score)
            self.model.score_alternatives_by_performance()

        # --- Step 4: Finalize results ---
        self.rankings = self.model.get_rankings()
        self.consistency_report = self.model.check_consistency()

        print("--- Workflow complete. Results are available in pipeline attributes. ---")
        return self
