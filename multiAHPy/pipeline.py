from __future__ import annotations
from typing import List, Dict, Any, Literal, Tuple
from copy import deepcopy
import json
import numpy as np
from .model import Hierarchy, Node
from .types import NumericType, TFN, Crisp, IFN, TrFN, GFN, IT2TrFN
from .aggregation import aggregate_matrices, aggregate_priorities
from .matrix_builder import rebuild_consistent_matrix, create_matrix_from_list, create_comparison_matrix, FuzzyScale, complete_matrix_from_upper_triangle
from .completion import complete_matrix
from .consistency import Consistency
from .sanitization import DataSanitizer


TYPE_MAP = {
    "Crisp": Crisp, "TFN": TFN, "IFN": IFN, "TrFN": TrFN, "GFN": GFN, "IT2TrFN": IT2TrFN
}

WorkflowType = Literal["ranking", "scoring"]
GroupStrategy = Literal["aggregate_judgments", "aggregate_priorities"]


class Workflow:
    """
    A pipeline for executing a complete AHP analysis from data to results.

    This class encapsulates the entire sequence of operations for a specific AHP
    workflow, ensuring that steps are not missed and that the process is
    reproducible. It's inspired by scikit-learn's Pipeline object.

    Workflow Steps:
    1. Initialize the workflow with a hierarchy structure and a full method recipe.
    2. Provide the necessary data (expert matrices or performance scores).
    3. Run the pipeline to get the final results.

    """

    def __init__(
        self,
        root_node: Node,
        workflow_type: WorkflowType,
        recipe: Dict[str, Any],
        alternatives: List[str],
        group_strategy: GroupStrategy = "aggregate_judgments",
        completion_method: str | None = None
    ):
        """
        Initializes the AHP Workflow Pipeline.

        Args:
            root_node: The root node of the AHP hierarchy structure.
            workflow_type: The type of analysis to perform.
                           - 'ranking': Classic AHP to rank alternatives via pairwise comparison.
                           - 'scoring': AHP as a weighting engine to score alternatives on performance data.
            recipe: A dictionary of methods, typically generated by `ahp.suggester`.
                    Must contain 'number_type', 'aggregation_method', 'weight_derivation_method'.
            alternatives: A list of the names of the alternatives.
        """
        if workflow_type not in ["ranking", "scoring"]:
            raise ValueError("workflow_type must be either 'ranking' or 'scoring'.")

        self.root_node = root_node
        self.workflow_type = workflow_type
        self.recipe = recipe
        self.alternatives_list = alternatives
        self.group_strategy = group_strategy

        self.model = Hierarchy(root_node, number_type=recipe['number_type'])
        for alt_name in alternatives:
            self.model.add_alternative(alt_name)

        self.expert_matrices: Dict[str, List[np.ndarray]] | None = None
        self.criteria_weights: Dict[str, Any] | None = None
        self.rankings: List[Tuple[str, float]] | None = None
        self.consistency_report: Dict[str, Any] | None = None

    def display(self):
        """
        Displays a horizontal, column-based HTML representation of the AHP hierarchy.
        """
        from .visualization import display_tree_hierarchy
        display_tree_hierarchy(self.model)

    @classmethod
    def from_json(cls, json_string: str) -> 'Workflow':
        """
        Parses a JSON string and executes the defined AHP workflow.

        Args:
            json_string: A string containing the full workflow definition in the
                         specified JSON schema.

        Returns:
            The fitted pipeline object with results.
        """
        data = json.loads(json_string)

        config = data['workflow_config']
        recipe = config['recipe']

        number_type_str = recipe.get("number_type", "Crisp")
        number_type = TYPE_MAP.get(number_type_str)
        if not number_type:
            raise ValueError(f"Unsupported number_type in JSON recipe: '{number_type_str}'")
        recipe['number_type'] = number_type

        root_node = Node.from_dict(data['hierarchy'])
        alternatives = [alt['name'] for alt in data['alternatives']]

        pipeline = cls(
            root_node=root_node,
            workflow_type=config['workflow_type'],
            recipe=recipe,
            alternatives=alternatives,
            group_strategy=config.get('group_strategy', 'aggregate_judgments'),
            completion_method=config.get('completion_method')
        )

        expert_matrices: Dict[str, List[np.ndarray]] = {}
        expert_weights: List[float] = []

        if 'expert_judgments' in data:
            all_matrix_nodes = set()
            for expert_data in data['expert_judgments']:
                all_matrix_nodes.update(expert_data['matrices'].keys())

            for node_id in all_matrix_nodes:
                expert_matrices[node_id] = []

            for expert_data in data['expert_judgments']:
                expert_weights.append(expert_data.get('weight'))
                for node_id, matrix_data in expert_data['matrices'].items():
                    matrix = create_matrix_from_list(matrix_data[0], number_type)
                    expert_matrices[node_id].append(matrix)

        if all(w is not None for w in expert_weights):
            weight_sum = sum(expert_weights)
            if weight_sum > 0:
                expert_weights = [w / weight_sum for w in expert_weights]
        else:
            expert_weights = None

        pipeline.run(
            expert_matrices=expert_matrices,
            performance_scores=data.get('performance_scores'),
            expert_weights=expert_weights
        )

        return pipeline

    def _create_model_instance(self) -> Hierarchy:
        """
        Creates a fresh, deep-copied instance of the Hierarchy model.

        This ensures that each expert calculation in the 'aggregate_priorities'
        strategy is completely isolated and does not modify a shared model object.
        It uses the template structure and recipe defined when the pipeline
        was initialized.
        """
        model_instance = Hierarchy(
            root_node=deepcopy(self.model.root),
            number_type=self.recipe['number_type']
        )
        for alt_name in self.alternatives_list:
            model_instance.add_alternative(alt_name)
        return model_instance

    def fit_weights(self, expert_matrices: Dict[str, List[np.ndarray]], expert_weights: List[float] | None = None, consistency_check: List[str] = ["saaty_cr", "gci"]):
        """
        Calculates the final criteria weights and checks consistency based on the chosen group strategy.

        This method populates the pipeline with `self.criteria_weights` and `self.consistency_report`.
        """
        self.expert_matrices = expert_matrices
        print(f"\n--- Fitting Weights (Strategy: {self.group_strategy}) ---")
        self.consistency_report = {}

        if self.group_strategy == "aggregate_judgments":
            aggregated_matrices = {}
            agg_method = self.recipe.get('aggregation_method', 'geometric')

            for node_id, matrices in expert_matrices.items():
                if not self.model._find_node(node_id).is_leaf:
                    agg_matrix = aggregate_matrices(matrices, method=agg_method, expert_weights=expert_weights, number_type=self.model.number_type) \
                                if len(matrices) > 1 else matrices[0]
                    aggregated_matrices[node_id] = agg_matrix
                    self.model.set_comparison_matrix(node_id, agg_matrix)

            self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
            print("  - Checking consistency of the aggregated model...")
            self.consistency_report['aggregated_model'] = self.model.check_consistency(required_indices=consistency_check)

        elif self.group_strategy == "aggregate_priorities":
            num_experts = len(list(expert_matrices.values())[0])
            print(f"  - Checking consistency for {num_experts} individual experts...")

            for i in range(num_experts):
                expert_name = f"expert_{i+1}"
                expert_model = self._create_model_instance()
                for node_id, matrices in expert_matrices.items():
                    if not expert_model._find_node(node_id).is_leaf:
                        expert_model.set_comparison_matrix(node_id, matrices[i])
                self.consistency_report[expert_name] = expert_model.check_consistency(required_indices=consistency_check)

            criteria_matrices_per_node = {
                node_id: matrices for node_id, matrices in expert_matrices.items()
                if not self.model._find_node(node_id).is_leaf
            }
            final_crisp_weights = self._calculate_aip_weights(criteria_matrices_per_node, expert_weights)
            self._set_final_weights_on_model(final_crisp_weights)

        self.criteria_weights = self.model.get_criteria_weights()
        print("--- Weight fitting complete. ---")
        return self

    def fit_weights_experimental(self,
                                expert_matrices: Dict[str, List[np.ndarray]],
                                expert_weights: List[float] | None = None,
                                consistency_check: List[str] = ["saaty_cr", "gci"],
                                revise_consistency: bool = False,
                                target_cr: float = 0.1,
                                revision_strategy: str = "adjust_bounded",
                                max_cycles: int = 50,
                                hesitation_factor: float = 0.2,
                                base_hesitation: float = 0.05
                                ):
        """
        Calculates the final criteria weights and checks consistency based on the chosen group strategy.

        This method populates the pipeline with `self.criteria_weights` and `self.consistency_report`.
        """
        self.expert_matrices = expert_matrices
        print(f"\n--- Fitting Weights (Strategy: {self.group_strategy}) ---")
        self.consistency_report = {}

        if self.group_strategy == "crisp_then_fuzzy":
            print("\n--- Running Crisp-then-Fuzzy Aggregation Strategy ---")

            num_experts = len(list(expert_matrices.values())[0])
            crisp_expert_matrices_list = []

            # 1. Defuzzify all expert matrices to crisp
            for i in range(num_experts):
                expert_dict = {}
                for node_id, matrices in expert_matrices.items():
                    matrix = matrices[i]
                    if matrix.dtype == object and hasattr(matrix[0, 0], 'defuzzify'):
                        expert_dict[node_id] = np.array([[c.defuzzify() for c in row] for row in matrix])
                    else:
                        expert_dict[node_id] = np.array(matrix, dtype=float)
                crisp_expert_matrices_list.append(expert_dict)

            # 2. CAPTURE RAW CONSISTENCY (CR)
            # We calculate this NOW, before sanitization changes the values.
            # This ensures hesitation reflects the ORIGINAL confusion of the expert.
            raw_consistency_map = {} # {node_id: [cr_expert1, cr_expert2, ...]}

            for node_id in expert_matrices.keys():
                if self.model._find_node(node_id).is_leaf: continue

                raw_consistency_map[node_id] = []
                for i in range(num_experts):
                    # Get the raw crisp matrix
                    raw_crisp = crisp_expert_matrices_list[i][node_id]

                    # Wrap in Crisp objects for consistency calculator
                    temp_obj = np.array([[Crisp(x) for x in row] for row in raw_crisp], dtype=object)
                    cr = Consistency.calculate_saaty_cr(temp_obj)
                    raw_consistency_map[node_id].append(cr)

            # 3. Sanitize (if enabled)
            # This alters the crisp values to be consistent, but we have already saved the
            # "bad" CRs to generate the hesitation later.
            if revise_consistency:
                print("\n  - Activating consistency revision for each expert...")
                sanitizer = DataSanitizer(
                    strategy=revision_strategy,
                    target_cr=target_cr,
                    max_cycles=max_cycles
                )

                reformatted = {node_id: [] for node_id in expert_matrices.keys()}
                for expert_dict in crisp_expert_matrices_list:
                    for node_id, matrix in expert_dict.items():
                        crisp_obj = np.array([[Crisp(c) for c in row] for row in matrix], dtype=object)
                        reformatted[node_id].append(crisp_obj)

                sanitized_fuzzy, _ = sanitizer.transform(reformatted, self.root_node, Crisp)

                # Update our working list with the SANITIZED crisp matrices
                crisp_expert_matrices_list = []
                for i in range(num_experts):
                    expert_dict = {
                        nid: np.array([[c.defuzzify() for c in row] for row in mats[i]])
                        for nid, mats in sanitized_fuzzy.items()
                    }
                    crisp_expert_matrices_list.append(expert_dict)

            # 4. INDIVIDUAL FUZZIFICATION & AGGREGATION
            print(f"\n  - Individually fuzzifying {num_experts} experts based on RAW CR...")
            target_type = self.recipe['number_type']

            for node_id in expert_matrices.keys():
                if self.model._find_node(node_id).is_leaf: continue

                fuzzy_matrices_to_aggregate = []

                for i in range(num_experts):
                    # A. Get the SANITIZED Values
                    crisp_matrix_float = crisp_expert_matrices_list[i][node_id]
                    rows, cols = crisp_matrix_float.shape

                    # B. Get the RAW Hesitation (from original input)
                    original_cr = raw_consistency_map[node_id][i]

                    # C. Create Fuzzy Matrix
                    # Combines: Correct Logic (Sanitized Value) + True Uncertainty (Raw CR)
                    expert_fuzzy_matrix = np.empty((rows, cols), dtype=object)

                    for r in range(rows):
                        for c in range(cols):
                            val = crisp_matrix_float[r, c]

                            if target_type.__name__ == 'IFN':
                                expert_fuzzy_matrix[r, c] = IFN.from_saaty_with_consistency(
                                    val,
                                    matrix_cr=original_cr, # <-- Use the high CR here
                                    hesitation_factor=hesitation_factor,
                                    base_hesitation=base_hesitation
                                )
                            else:
                                expert_fuzzy_matrix[r, c] = target_type.from_saaty(val)

                    fuzzy_matrices_to_aggregate.append(expert_fuzzy_matrix)

                # 5. AGGREGATE
                agg_method = self.recipe.get('aggregation_method', 'geometric')

                final_fuzzy_matrix = aggregate_matrices(
                    fuzzy_matrices_to_aggregate,
                    method=agg_method,
                    expert_weights=expert_weights,
                    number_type=target_type
                )

                self.model.set_comparison_matrix(node_id, final_fuzzy_matrix)

            self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
            self.consistency_report['final_aggregated_model'] = self.model.check_consistency()

        elif self.group_strategy == "aggregate_judgments":
            aggregated_matrices = {}
            agg_method = self.recipe.get('aggregation_method', 'geometric')

            for node_id, matrices in expert_matrices.items():
                if not self.model._find_node(node_id).is_leaf:
                    agg_matrix = aggregate_matrices(matrices, method=agg_method, expert_weights=expert_weights, number_type=self.model.number_type) \
                                if len(matrices) > 1 else matrices[0]
                    aggregated_matrices[node_id] = agg_matrix
                    self.model.set_comparison_matrix(node_id, agg_matrix)

            self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
            self.consistency_report['aggregated_model'] = self.model.check_consistency()

        elif self.group_strategy == "aggregate_priorities":
             # Reuse standard AIP logic if needed, or implement here for 'experimental' context
             pass

        self.criteria_weights = self.model.get_criteria_weights()
        print("--- Weight fitting complete. ---")
        return self

    def fit_weights_retired(self,
                                expert_matrices: Dict[str, List[np.ndarray]],
                                expert_weights: List[float] | None = None,
                                consistency_check: List[str] = ["saaty_cr", "gci"],
                                revise_consistency: bool = False,
                                target_cr: float = 0.1,
                                revision_strategy: str = "adjust_bounded",
                                max_cycles: int = 50
                                ):
        """
        Calculates the final criteria weights and checks consistency based on the chosen group strategy.

        This method populates the pipeline with `self.criteria_weights` and `self.consistency_report`.
        """
        self.expert_matrices = expert_matrices
        print(f"\n--- Fitting Weights (Strategy: {self.group_strategy}) ---")
        self.consistency_report = {}
        if self.group_strategy == "crisp_then_fuzzy":
            print("\n--- Running Crisp-then-Fuzzy Aggregation Strategy ---")

            # 1. Defuzzify all expert matrices to crisp
            num_experts = len(list(expert_matrices.values())[0])
            crisp_expert_matrices_list = []
            for i in range(num_experts):
                expert_dict = {
                    node_id: np.array([[c.defuzzify() for c in row] for row in matrices[i]])
                    for node_id, matrices in expert_matrices.items()
                }
                crisp_expert_matrices_list.append(expert_dict)

            # 2. OPTIONAL: Sanitize each expert's set of crisp matrices
            if revise_consistency:
                print("\n  - Activating consistency revision for each expert...")
                sanitizer = DataSanitizer(
                    strategy=revision_strategy,
                    target_cr=target_cr,
                    max_cycles=max_cycles
                )

                # The sanitizer needs the data in a different format, let's adapt it.
                # It expects {'node_id': [matrix_exp1, matrix_exp2, ...]}
                # We have [{node_id: matrix}, {node_id: matrix}, ...]
                # Let's reformat the data for the sanitizer
                reformatted_for_sanitizer = {node_id: [] for node_id in expert_matrices.keys()}
                for expert_dict in crisp_expert_matrices_list:
                    for node_id, matrix in expert_dict.items():
                        # We need to convert them to Crisp objects for the sanitizer
                        crisp_obj_matrix = np.array([[Crisp(c) for c in row] for row in matrix], dtype=object)
                        reformatted_for_sanitizer[node_id].append(crisp_obj_matrix)

                # Run the sanitization. It returns consistent fuzzy matrices.
                sanitized_fuzzy_matrices, _ = sanitizer.transform(
                    reformatted_for_sanitizer, self.root_node, Crisp
                )

                # Now, defuzzify them *back* to crisp for the aggregation step
                crisp_expert_matrices_list = []
                for i in range(num_experts):
                    expert_dict = {
                        node_id: np.array([[c.defuzzify() for c in row] for row in matrices[i]])
                        for node_id, matrices in sanitized_fuzzy_matrices.items()
                    }
                    crisp_expert_matrices_list.append(expert_dict)

            # 3. Aggregate the (now clean) crisp matrices
            print("\n  - Aggregating crisp matrices from all experts...")
            aggregated_crisp_matrices = {}
            for node_id in expert_matrices.keys():
                if self.model._find_node(node_id).is_leaf: continue

                # Stack all matrices for this node_id from each expert
                matrices_for_node = [expert_dict[node_id] for expert_dict in crisp_expert_matrices_list]
                stacked_matrices = np.stack(matrices_for_node)

                # Perform geometric mean aggregation
                log_matrices = np.log(np.maximum(stacked_matrices, 1e-9))
                avg_log_matrix = np.average(log_matrices, axis=0, weights=expert_weights)
                aggregated_crisp_matrix = np.exp(avg_log_matrix)
                aggregated_crisp_matrices[node_id] = aggregated_crisp_matrix

            # 4. Re-fuzzify and calculate weights
            print("\n  - Re-fuzzifying aggregated matrix and calculating final weights...")
            for node_id, matrix in aggregated_crisp_matrices.items():
                fuzzy_matrix = np.array(
                    [[self.recipe['number_type'].from_saaty(c) for c in row] for row in matrix],
                    dtype=object
                )
                self.model.set_comparison_matrix(node_id, fuzzy_matrix)

            self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
            self.consistency_report['final_aggregated_model'] = self.model.check_consistency()

        elif self.group_strategy == "aggregate_judgments":
            # STRATEGY 1: Aggregate Judgments First (AIJ)
            aggregated_matrices = {}
            agg_method = self.recipe.get('aggregation_method', 'geometric')

            for node_id, matrices in expert_matrices.items():
                if not self.model._find_node(node_id).is_leaf:
                    agg_matrix = aggregate_matrices(matrices, method=agg_method, expert_weights=expert_weights) \
                                if len(matrices) > 1 else matrices[0]
                    aggregated_matrices[node_id] = agg_matrix
                    self.model.set_comparison_matrix(node_id, agg_matrix)

            for node_id, matrix in aggregated_matrices.items():
                self.model.set_comparison_matrix(node_id, matrix)
            self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
            self.consistency_report['aggregated_model'] = self.model.check_consistency()

        elif self.group_strategy == "aggregate_priorities":
            # STRATEGY 2: Aggregate Priorities (AIP)

            num_experts = len(list(expert_matrices.values())[0])
            print(f"  - Checking consistency for {num_experts} individual experts...")

            for i in range(num_experts):
                expert_name = f"expert_{i+1}"
                expert_model = Hierarchy(self.model.root, number_type=self.recipe['number_type'])

                for node_id, matrices in expert_matrices.items():
                    if not expert_model._find_node(node_id).is_leaf:
                        expert_model.set_comparison_matrix(node_id, matrices[i])

                self.consistency_report[expert_name] = expert_model.check_consistency(required_indices=consistency_check)

            criteria_matrices_per_node = {
                node_id: matrices for node_id, matrices in expert_matrices.items()
                if not self.model._find_node(node_id).is_leaf
            }
            final_crisp_weights_per_node = self._calculate_aip_weights(criteria_matrices_per_node, expert_weights)

            # 3. Manually set the final weights on the model's nodes
            self._set_final_weights_on_model(final_crisp_weights_per_node)

            # 4. --- NEW: RECONSTRUCT THE AGGREGATED MATRICES FOR REPORTING ---
            print("\n  - Reconstructing final aggregated matrices from AIP weights for reporting...")
            number_type = self.recipe['number_type']
            for node_id, crisp_weights in final_crisp_weights_per_node.items():
                # Create a dummy inconsistent matrix to pass to the rebuild function
                # (The function only needs the weights, so the matrix content doesn't matter)
                # A better way is to create a matrix from weights directly.
                n = len(crisp_weights)

                # Create the matrix directly: a_ij = w_i / w_j
                reconstructed_crisp_matrix = np.array([
                    [crisp_weights[i] / crisp_weights[j] for j in range(n)] for i in range(n)
                ])

                # Convert to the fuzzy type
                reconstructed_fuzzy_matrix = np.array(
                    [[number_type.from_saaty(c) for c in row] for row in reconstructed_crisp_matrix],
                    dtype=object
                )

                self.model.set_comparison_matrix(node_id, reconstructed_fuzzy_matrix)

        self.criteria_weights = self.model.get_criteria_weights()
        print("--- Weight fitting complete. ---")

        return self


    def _fit_weights_aij(self, expert_matrices, expert_weights, consistency_check=["saaty_cr", "gci"]):
        """Fits weights using Aggregation of Individual Judgments."""
        aggregated_matrices = self._aggregate_expert_matrices(expert_matrices, expert_weights)

        for node_id, matrix in aggregated_matrices.items():
            self.model.set_comparison_matrix(node_id, matrix)

        self.model.calculate_weights(method=self.recipe['weight_derivation_method'])
        self.consistency_report = self.model.check_consistency(required_indices=consistency_check)

    def _fit_weights_aip(self, expert_matrices: Dict[str, List[np.ndarray]], expert_weights: List[float] | None = None):
        """
        Fits weights using Aggregation of Individual Priorities (AIP).
        """
        num_experts = len(list(expert_matrices.values())[0])
        individual_criteria_weights = []
        for i in range(num_experts):
            expert_model = self._create_model_instance()
            for node_id, matrices in expert_matrices.items():
                node = expert_model._find_node(node_id)
                if node and not node.is_leaf:
                    expert_model.set_comparison_matrix(node_id, matrices[i])
            expert_model.calculate_weights(method=self.recipe['weight_derivation_method'])
            crisp_weights_vector = list(expert_model.get_criteria_weights(as_dict=True).values())
            individual_criteria_weights.append(crisp_weights_vector)

        print("  - Aggregating individual criteria weight vectors...")
        weights_matrix = np.array(individual_criteria_weights)

        final_group_weights_vector = np.average(weights_matrix, axis=0, weights=expert_weights)
        final_group_weights_vector /= np.sum(final_group_weights_vector)

        print("  - Checking consistency for each expert's judgments...")
        from .consistency import Consistency
        template_model = self._create_model_instance()
        criteria_matrices = {nid: m for nid, m in expert_matrices.items() if not template_model._find_node(nid).is_leaf}
        defuzz_method_for_consistency = self.recipe.get('consistency_method', 'centroid')

        self.consistency_report = Consistency.check_group_consistency(
            model=template_model,
            expert_matrices=criteria_matrices,
            consistency_method=defuzz_method_for_consistency
        )
        leaf_nodes = self._create_model_instance().root.get_all_leaf_nodes()
        leaf_ids = [node.id for node in leaf_nodes]
        final_weights_dict = dict(zip(leaf_ids, final_group_weights_vector))
        self.criteria_weights = dict(zip(leaf_ids, final_group_weights_vector))

        return final_weights_dict

    def _score_by_performance(self, performance_scores):
        if self.group_strategy == 'aggregate_priorities':
            self._score_by_performance_aip(performance_scores)
        else:
            self._score_by_performance_aij(performance_scores)

    def _score_by_performance_aip(self, performance_scores: Dict[str, Dict[str, float]]):
        """
        (Private Helper) Scores alternatives using pre-aggregated AIP weights.
        This is a direct application of weights to performance data.
        """
        print("  - Applying aggregated priority (AIP) weights to performance scores...")

        for alt_obj in self.model.alternatives:
            alt_name = alt_obj.name

            if alt_name not in performance_scores:
                raise ValueError(f"Missing performance data for alternative '{alt_name}'.")

            alt_perf_data = performance_scores[alt_name]
            overall_score = 0.0

            for leaf_id, weight in self.criteria_weights.items():
                try:
                    # Score = weight of criterion * performance on that criterion
                    performance_value = alt_perf_data[leaf_id]
                    overall_score += weight * performance_value
                except KeyError:
                    raise KeyError(f"Missing performance score for alternative '{alt_name}' on criterion '{leaf_id}'.")

            alt_obj.overall_score = self.model.number_type.from_normalized(overall_score)

    def _score_by_performance_aij(self, performance_scores: Dict[str, Dict[str, float]]):
        """
        (Private Helper) Scores alternatives for the AIJ workflow.
        This delegates to the model's internal recursive calculation.
        """
        print("  - Applying aggregated judgment (AIJ) weights to performance scores...")
        for alt_name, scores in performance_scores.items():
            alt_obj = self.model.get_alternative(alt_name)
            for leaf_id, score in scores.items():
                alt_obj.set_performance_score(leaf_id, score)

        self.model.score_alternatives_by_performance()

    def _rank_by_comparison(self, alternative_matrices, expert_weights=None):
        """Ranks alternatives using pairwise comparison matrices."""
        aggregated_alt_matrices = self._aggregate_expert_matrices(alternative_matrices, expert_weights)

        for leaf_id, matrix in aggregated_alt_matrices.items():
            self.model.set_alternative_matrix(leaf_id, matrix)

        self.model.rank_alternatives_by_comparison(derivation_method=self.recipe['weight_derivation_method'])

    def _rank_by_comparison_aip(self, expert_matrices: Dict[str, List[np.ndarray]], expert_weights: List[float] | None = None):
        """
        (Private Helper) Ranks alternatives using the AIP strategy.
        This involves solving the full AHP model for each expert and aggregating
        the final ranking vectors.
        """
        print("  - Solving full AHP model for each expert (AIP strategy)...")
        num_experts = len(list(expert_matrices.values())[0])

        individual_ranking_vectors = []

        for i in range(num_experts):
            print(f"    - Solving for Expert {i+1}...")

            expert_model = self._create_model_instance()

            for node_id, matrices in expert_matrices.items():
                node = expert_model._find_node(node_id)
                if not node: continue
                if node.is_leaf:
                    expert_model.set_alternative_matrix(node_id, matrices[i])
                else:
                    expert_model.set_comparison_matrix(node_id, matrices[i])

            expert_model.calculate_weights(method=self.recipe['weight_derivation_method'])
            expert_model.rank_alternatives_by_comparison(derivation_method=self.recipe['weight_derivation_method'])

            expert_ranks = expert_model.get_rankings(consistency_method=self.recipe.get('consistency_method', 'centroid'))
            score_dict = dict(expert_ranks)
            ordered_scores = [score_dict[alt_name] for alt_name in self.alternatives]
            individual_ranking_vectors.append(ordered_scores)

        print("  - Aggregating individual final rankings...")
        rankings_matrix = np.array(individual_ranking_vectors)
        final_group_scores = np.average(rankings_matrix, axis=0, weights=expert_weights)

        for i, alt_obj in enumerate(self.model.alternatives):
            alt_obj.overall_score = self.model.number_type.from_normalized(final_group_scores[i])

        # Also set the consistency report (e.g., from the first expert as a sample)
        # A full implementation would run this for all experts.
        # ... (logic to generate group consistency table) ...

    def _aggregate_expert_matrices(self, expert_matrices, expert_weights):
        """Helper to aggregate a dictionary of expert matrices."""
        aggregated_data = {}
        aggregation_method = self.recipe.get('aggregation_method', 'geometric')
        for node_id, matrices in expert_matrices.items():
            if len(matrices) > 1:
                print(f"  - Aggregating {len(matrices)} matrices for node '{node_id}'...")
                agg_matrix = aggregate_matrices(matrices, method=aggregation_method, expert_weights=expert_weights, number_type=self.model.number_type)
                aggregated_data[node_id] = agg_matrix
            elif matrices:
                aggregated_data[node_id] = matrices[0]
        return aggregated_data

    def _calculate_aip_weights(
        self,
        criteria_matrices_per_node: Dict[str, List[np.ndarray]],
        expert_weights: List[float] | None
    ) -> Dict[str, np.ndarray]:
        """Helper to manage the complexity of the Aggregate Priorities workflow."""
        final_weights = {}
        for node_id, matrices in criteria_matrices_per_node.items():
            aggregated_vector = aggregate_priorities(
                matrices,
                method=self.recipe['weight_derivation_method'],
                expert_weights=expert_weights
            )
            final_weights[node_id] = aggregated_vector
        return final_weights

    def _set_final_weights_on_model(self, final_crisp_weights: Dict[str, np.ndarray]):
        """
        Manually sets the local and global weights on the main model after the AIP workflow.
        This version correctly handles multi-level hierarchies.
        """
        number_type = self.recipe['number_type']

        def recursive_setter(node: Node):
            if node.id in final_crisp_weights:
                child_weights = final_crisp_weights[node.id]
                for i, child in enumerate(node.children):
                    child.local_weight = number_type.from_normalized(child_weights[i])

            for child in node.children:
                if child.local_weight and node.global_weight:
                    child.global_weight = node.global_weight * child.local_weight
                recursive_setter(child)

        root = self.model.root
        root.local_weight = number_type.multiplicative_identity()
        root.global_weight = number_type.multiplicative_identity()
        recursive_setter(root)

    def score(self, performance_scores: Dict[str, Dict[str, float]] | None = None) -> 'Workflow':
        """
        Runs the final scoring step of the 'scoring' workflow.
        Requires `fit_weights` to have been called first.
        """
        if self.workflow_type != "scoring":
             raise TypeError("The .score() method is only for the 'scoring' workflow.")

        if performance_scores:
             for alt_name, scores in performance_scores.items():
                  alt_obj = self.model.get_alternative(alt_name)
                  for leaf_id, score_val in scores.items():
                       alt_obj.set_performance_score(leaf_id, score_val)

        self.model.score_alternatives_by_performance()
        self.rankings = self.model.get_rankings()
        return self

    def run(self, expert_matrices, performance_scores=None, expert_weights=None):
        """
        Executes the entire AHP pipeline with the provided data in one call.

        This is a convenience method that calls the appropriate sequence of
        `fit_weights`, `score`, or `rank` methods based on the workflow's
        configuration.

        Args:
            expert_matrices: A dictionary mapping a node ID to a list of expert
                             comparison matrices. Required for both workflows.
            performance_scores: A dictionary mapping an alternative name to its
                                performance scores. Required for 'scoring' workflow.
            expert_weights: Optional list of weights for the experts.

        Returns:
            The fitted pipeline object, with results in its attributes.
        """
        criteria_matrices = {nid: m for nid, m in expert_matrices.items() if not self.model._find_node(nid).is_leaf}
        self.fit_weights(criteria_matrices, expert_weights)

        if self.workflow_type == 'ranking':
            alt_matrices = {nid: m for nid, m in expert_matrices.items() if self.model._find_node(nid).is_leaf}
            self.rank(alt_matrices, expert_weights)
        elif self.workflow_type == 'scoring':
            self.score(performance_scores)
        return self

    def rank(self, alternative_matrices: Dict[str, List[np.ndarray]], expert_weights: List[float] | None = None) -> 'Workflow':
        """Runs the final ranking step of the 'ranking' workflow."""
        if self.workflow_type != "ranking":
             raise TypeError("The .rank() method is only for the 'ranking' workflow.")

        agg_method = self.recipe.get('aggregation_method', 'geometric')
        for leaf_id, matrices in alternative_matrices.items():
             agg_matrix = aggregate_matrices(matrices, method=agg_method, expert_weights=expert_weights, number_type=self.model.number_type) \
                          if len(matrices) > 1 else matrices[0]
             self.model.set_alternative_matrix(leaf_id, agg_matrix)

        self.model.rank_alternatives_by_comparison(derivation_method=self.recipe['weight_derivation_method'])
        self.rankings = self.model.get_rankings()
        return self

    def make_consistent(self, **kwargs):
        """
        Creates and runs a DataSanitizer to revise the expert matrices.
        This method is a convenience wrapper around the DataSanitizer class.
        """
        if self.expert_matrices is None:
            raise RuntimeError("Run .fit_weights() first.")
        sanitizer = DataSanitizer(**kwargs)
        sanitized_matrices, change_log = sanitizer.transform(
            self.expert_matrices, self.root_node, self.recipe['number_type']
        )
        self.expert_matrices = sanitized_matrices
        self.fit_weights(self.expert_matrices)
        return change_log

    def make_consistent_retired(
        self,
        target_cr: float | None = None,
        max_cycles: int = 50,
        strategy: Literal["adjust_optimal", "adjust_bounded", "remove_and_complete"] = "adjust_bounded",
        bound: float = 9.0,
        completion_method: str = "llsm"
    ) -> Dict[str, Any]:
        """
        Automatically revises inconsistent matrices until they meet an acceptable consistency threshold.

        This method iteratively finds the single most inconsistent matrix in the dataset,
        applies a revision to its most inconsistent judgment, and repeats the process
        until all matrices are acceptably consistent or the cycle limit is reached.

        Args:
            target_cr (float, optional): The target Saaty's Consistency Ratio. If None, uses
                                         the default from the global configure_parameters. Defaults to None.
            max_cycles (int, optional): The maximum number of revision cycles to run to prevent
                                        infinite loops. Defaults to 50.
            strategy (str, optional): The method for fixing an inconsistent judgment.
                - 'adjust_optimal': Replaces the value with the pure mathematical ideal,
                                    issuing a warning if it's outside the Saaty scale.
                - 'adjust_bounded': (Default) Replaces the value with the ideal, but
                                    clipped to the [1/bound, bound] scale.
                - 'remove_and_complete': Treats the judgment as missing and uses a completion
                                         algorithm to estimate a new value for the whole matrix.
            bound (float, optional): The upper limit for the Saaty scale (e.g., 9.0), used by
                                     the 'adjust_optimal' and 'adjust_bounded' strategies.
            completion_method (str, optional): The completion algorithm to use if
                                             `strategy` is 'remove_and_complete'.

        Returns:
            A dictionary logging all the changes that were made.
        """
        from .config import configure_parameters

        if self.consistency_report is None:
            raise RuntimeError("Consistency not checked. Run .fit_weights() before .make_consistent().")
        if self.expert_matrices is None:
            raise RuntimeError("Expert matrices not stored. Cannot perform revisions.")

        final_target_cr = target_cr if target_cr is not None else configure_parameters.DEFAULT_SAATY_CR_THRESHOLD

        print(f"\n--- Revising matrices to meet CR <= {final_target_cr} (Strategy: {strategy}) ---")

        change_log = {}

        for revision_cycle in range(max_cycles):
            matrices_to_fix = []
            for expert_id, report in self.consistency_report.items():
                for node_id, metrics in report.items():
                    cr_val = metrics.get('saaty_cr')
                    if isinstance(cr_val, (float, np.floating)) and cr_val > final_target_cr:
                        matrices_to_fix.append({
                            "expert_id": expert_id,
                            "node_id": node_id,
                            "cr": cr_val
                        })

            if not matrices_to_fix:
                print(f"\n✅ All matrices meet the consistency target (CR <= {final_target_cr}).")
                break

            print(f"\nCycle {revision_cycle + 1}/{max_cycles}: Found {len(matrices_to_fix)} inconsistent matrices to revise.")

            change_made_in_cycle = False

            for matrix_info in matrices_to_fix:
                expert_id = matrix_info['expert_id']
                node_id = matrix_info['node_id']
                num_expert = int(expert_id.split('_')[-1]) - 1
                original_matrix = self.expert_matrices[node_id][num_expert]

                temp_model = Hierarchy(self.model.root, number_type=self.recipe['number_type'])
                temp_model.set_comparison_matrix(node_id, original_matrix)
                recommendations = Consistency.get_consistency_recommendations(temp_model, node_id)

                if "error" in recommendations or not recommendations.get("revisions"):
                    print(f"  - Warning: Could not generate a recommendation for {expert_id}/{node_id}. Skipping this matrix for this cycle.")
                    continue

                top_rec = recommendations['revisions'][0]
                i, j = top_rec['pair']
                old_value = top_rec['current_value']
                ideal_value = top_rec['suggested_value']

                number_type = self.recipe['number_type']
                new_value = None

                if strategy == "adjust_optimal":
                    new_value = ideal_value
                    if not (1/bound <= ideal_value <= bound):
                        print(f"    - [Adjust Optimal] Fixing {expert_id}/{node_id}: Warning - suggested value {new_value:.2f} is out of scale.")
                    original_matrix[i, j] = number_type.from_saaty(new_value)
                    original_matrix[j, i] = number_type.from_saaty(1 / new_value)
                    change_made_in_cycle = True

                elif strategy == "adjust_bounded":
                    new_value = np.clip(ideal_value, 1/bound, bound)
                    original_matrix[i, j] = number_type.from_saaty(new_value)
                    original_matrix[j, i] = number_type.from_saaty(1 / new_value)
                    change_made_in_cycle = True

                elif strategy == "remove_and_complete":
                    matrix_with_missing = original_matrix.copy()
                    matrix_with_missing[i, j] = None
                    matrix_with_missing[j, i] = None

                    completed_numeric = complete_matrix(matrix_with_missing, method=completion_method)
                    new_value = completed_numeric[i, j]

                    n = original_matrix.shape[0]
                    for r in range(n):
                        for c in range(n):
                            original_matrix[r, c] = number_type.from_normalized(completed_numeric[r, c])
                    change_made_in_cycle = True

                if change_made_in_cycle:
                    log_key = f"{expert_id}_{node_id}"
                    if log_key not in change_log: change_log[log_key] = []
                    change_log[log_key].append({'from': old_value, 'to': new_value, 'pair': (i, j), 'cycle': revision_cycle + 1})

            if change_made_in_cycle:
                print("  - Cycle complete. Re-calculating weights and consistency for all experts...")
                self.fit_weights(self.expert_matrices)
            else:
                print("  - Warning: No further improvements could be made. Halting revision process.")
                break

        else:
            print(f"\n⚠️ Warning: Reached max_cycles ({max_cycles}) limit. Not all matrices may be consistent.")

        final_inconsistent_count = 0
        if self.consistency_report:
            for report in self.consistency_report.values():
                for metrics in report.values():
                    cr_val = metrics.get('saaty_cr')
                    if isinstance(cr_val, (float, np.floating)) and cr_val > final_target_cr:
                        final_inconsistent_count += 1

        if final_inconsistent_count > 0:
            print(f"\n⚠️ Final Status: {final_inconsistent_count} matrices still exceed the CR target of {final_target_cr}.")
        else:
            print(f"\n✅ Final Status: All matrices were successfully revised to meet the consistency target.")

        return change_log

    def sanitize_expert_data(
        self,
        expert_matrices: Dict[str, List[np.ndarray]],
        target_cr: float = 0.1,
        max_cycles: int = 40,
        strategy: Literal["adjust_bounded", "remove_and_complete"] = "adjust_bounded",
        completion_method: str = "llsm"
    ) -> Dict[str, List[np.ndarray]]:
        """
        Pre-processes expert matrices by enforcing consistency on each one individually.

        This method follows a robust sanitization workflow:
        1. Converts each fuzzy matrix to a crisp representation.
        2. Iteratively revises the crisp matrix until it meets the target_cr.
        3. Converts the now-consistent crisp matrix back to the original fuzzy type.

        This is ideal for cleaning data from non-expert groups before aggregation.

        Args:
            expert_matrices: The raw dictionary of expert fuzzy matrices.
            target_cr (float): The consistency threshold to achieve.
            max_cycles (int): Max revision attempts per matrix.
            strategy (str): The revision strategy to use on the crisp matrices.
            completion_method (str): The completion method for the 'remove_and_complete' strategy.

        Returns:
            A new dictionary of expert matrices, where each matrix is now acceptably consistent.
        """
        print("\n--- Sanitizing Expert Data: Enforcing Consistency ---")

        sanitized_matrices = {node_id: [] for node_id in expert_matrices}
        original_number_type = self.recipe['number_type']
        num_experts = len(list(expert_matrices.values())[0])

        for i in range(num_experts):
            expert_id = f"expert_{i+1}"
            print(f"\nProcessing {expert_id}...")

            # Create a temporary, single-expert pipeline that works with CRISP data
            crisp_pipeline = Workflow(
                root_node=self.model.root,
                workflow_type=self.workflow_type,
                group_strategy="aggregate_priorities", # Strategy doesn't matter for one expert
                recipe={'number_type': Crisp}, # <-- Work in the crisp domain
                alternatives=[alt.name for alt in self.model.alternatives]
            )

            # Build the set of matrices for this single expert
            single_expert_matrices = {}
            for node_id, matrices in expert_matrices.items():
                # Defuzzify the matrix to create the crisp input
                fuzzy_matrix = matrices[i]
                crisp_matrix_raw = np.array([[cell.defuzzify() for cell in row] for row in fuzzy_matrix])
                single_expert_matrices[node_id] = [crisp_matrix_raw]

            # Fit weights to generate the initial consistency report for the crisp matrices
            crisp_pipeline.fit_weights(expert_matrices=single_expert_matrices)

            # Run the consistency revision on this expert's crisp data
            crisp_pipeline.make_consistent(
                target_cr=target_cr,
                max_cycles=max_cycles,
                strategy=strategy,
                completion_method=completion_method
            )

            # Now, extract the cleaned matrices and convert them back to the original fuzzy type
            for node_id in expert_matrices.keys():
                # `crisp_pipeline.expert_matrices` holds the revised crisp matrices
                consistent_crisp_matrix = crisp_pipeline.expert_matrices[node_id][0]

                n = consistent_crisp_matrix.shape[0]
                re_fuzzified_matrix = create_comparison_matrix(n, original_number_type)

                for r in range(n):
                    for c in range(n):
                        # Convert each crisp value back to a fuzzy number
                        # We use from_normalized to create a non-fuzzy fuzzy number (e.g., TFN(3,3,3))
                        # This preserves the now-consistent ratio.
                        crisp_val = consistent_crisp_matrix[r, c].value
                        re_fuzzified_matrix[r, c] = original_number_type.from_normalized(crisp_val)

                sanitized_matrices[node_id].append(re_fuzzified_matrix)

        print("\n--- Sanitization Complete ---")
        return sanitized_matrices
