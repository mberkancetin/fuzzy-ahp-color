{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXTqUhSgurnXR2f22YUk9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mberkancetin/fuzzy-ahp-color/blob/main/test/multiAHPy_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyBYZF2Wc9jH"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mberkancetin/fuzzy-ahp-color.git\n",
        "import sys\n",
        "sys.path.insert(0, '/content/fuzzy-ahp-color')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 1: FUZZY AHP DEMONSTRATION (COLOR Case)**"
      ],
      "metadata": {
        "id": "2CpsicoBMoDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Building the Hierarchy"
      ],
      "metadata": {
        "id": "BKyBGCncTa_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from multiAHPy.model import Node, Alternative, Hierarchy\n",
        "from multiAHPy.types import TFN, TrFN, Crisp, GFN, NumericType, Number\n",
        "from multiAHPy.validation import Validation\n",
        "from multiAHPy.consistency import Consistency\n",
        "\n",
        "goal = Node(\"Goal\", \"Corporate Local Responsibility (COLOR) Score\")\n",
        "criteria_nodes = {\n",
        "    \"C1\": Node(\"C1\", \"Generosity & Benevolence\"),\n",
        "    \"C2\": Node(\"C2\", \"Societal Demand\"),\n",
        "    \"C3\": Node(\"C3\", \"Compliance\"),\n",
        "    \"C4\": Node(\"C4\", \"Stakeholder Involvement\")\n",
        "}\n",
        "for c_node in criteria_nodes.values():\n",
        "    goal.add_child(c_node)\n",
        "\n",
        "sub_criteria_data = {\n",
        "    \"C1\": [\"C11\", \"C12\", \"C13\", \"C14\"],\n",
        "    \"C2\": [\"C21\", \"C22\", \"C23\", \"C24\"],\n",
        "    \"C3\": [\"C31\", \"C32\", \"C33\", \"C34\"],\n",
        "    \"C4\": [\"C41\", \"C42\", \"C43\", \"C44\"]\n",
        "}\n",
        "for parent_id, child_ids in sub_criteria_data.items():\n",
        "    for child_id in child_ids:\n",
        "        criteria_nodes[parent_id].add_child(Node(child_id))"
      ],
      "metadata": {
        "id": "uexUWV82TWGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal.__repr__()"
      ],
      "metadata": {
        "id": "RBhjFcKJaujM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal.children"
      ],
      "metadata": {
        "id": "VXLhP3uzZl5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal.children[0].children"
      ],
      "metadata": {
        "id": "Z9mRip6Ta8Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Instantiate the Model for FUZZY (TFN) operations ---\n",
        "    We explicitly tell the model it will be working with TFNs."
      ],
      "metadata": {
        "id": "N8kG_cjVTkaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_model = Hierarchy[TFN](root_node=goal, number_type=TFN)\n",
        "fuzzy_model.display()"
      ],
      "metadata": {
        "id": "vkpN8yaPT_WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Set FUZZY Comparison Matrices ---\n",
        "    In a real scenario, these would come from your surveys and be TFNs.\n",
        "    We will create mock TFN matrices for this demonstration."
      ],
      "metadata": {
        "id": "ucwbrF2HUFY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mock_tfn_matrix(size):\n",
        "    \"\"\"\n",
        "    Creates a mock TFN matrix that correctly follows the reciprocity rule.\n",
        "    \"\"\"\n",
        "    matrix = np.empty((size, size), dtype=object)\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            if i == j:\n",
        "                # Diagonal elements are always (1, 1, 1)\n",
        "                matrix[i, j] = TFN(1, 1, 1)\n",
        "            elif i < j: # Only fill the upper triangle with random values\n",
        "                val = np.random.uniform(1, 9)\n",
        "                matrix[i, j] = TFN(max(1, val-1), val, val+1)\n",
        "            else: # For the lower triangle, do nothing yet\n",
        "                continue\n",
        "\n",
        "    # Now, fill the lower triangle with the inverses of the upper triangle\n",
        "    for i in range(size):\n",
        "        for j in range(i + 1, size):\n",
        "            matrix[j, i] = matrix[i, j].inverse()\n",
        "\n",
        "    return matrix\n",
        "\n",
        "fuzzy_model.set_comparison_matrix(\"Goal\", create_mock_tfn_matrix(4))\n",
        "fuzzy_model.set_comparison_matrix(\"C1\", create_mock_tfn_matrix(4))\n",
        "fuzzy_model.set_comparison_matrix(\"C2\", create_mock_tfn_matrix(4))\n",
        "fuzzy_model.set_comparison_matrix(\"C3\", create_mock_tfn_matrix(4))\n",
        "fuzzy_model.set_comparison_matrix(\"C4\", create_mock_tfn_matrix(4))\n"
      ],
      "metadata": {
        "id": "H59RtrQvUeTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_model.root.children"
      ],
      "metadata": {
        "id": "L8SvN45FbOxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Check Matrix Consistencies"
      ],
      "metadata": {
        "id": "5MrsIc4tUgl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the new, cleaner method\n",
        "consistency_results = fuzzy_model.check_consistency(threshold=0.1)\n",
        "\n",
        "is_fully_consistent = True\n",
        "# The structure of the results dictionary is the same, so this loop works as is\n",
        "for node_id, result in consistency_results.items():\n",
        "    print(f\"  - Consistency for '{node_id}' matrix: CR = {result['consistency_ratio']:.4f} \"\n",
        "        f\"(Is Consistent: {result['is_consistent']})\")\n",
        "    if not result['is_consistent']:\n",
        "        is_fully_consistent = False\n",
        "\n",
        "if not is_fully_consistent:\n",
        "    print(\"\\nWARNING: One or more matrices are inconsistent...\")\n",
        "    # ... the rest of your error handling and recommendation logic ...\n",
        "else:\n",
        "    print(\"All matrices are consistent. Proceeding with calculations.\")\n",
        "print(Consistency.get_consistency_recommendations(fuzzy_model, \"C1\"))"
      ],
      "metadata": {
        "id": "pzwGpya8Ug_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Calculate Weights"
      ],
      "metadata": {
        "id": "KWgn9LpTUwyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_model.calculate_weights(method=\"geometric_mean\")"
      ],
      "metadata": {
        "id": "Nb_cifn_U2qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Add Alternatives with FUZZY Performance Scores"
      ],
      "metadata": {
        "id": "MNnukY4fVHst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "company_a_fuzzy = Alternative(\"Company A\")\n",
        "\n",
        "# Performance can also be uncertain. A score of 0.78 might be TFN(0.7, 0.78, 0.85)\n",
        "leaf_nodes = fuzzy_model.root.get_all_leaf_nodes()\n",
        "for leaf in leaf_nodes:\n",
        "    # Create random fuzzy scores for the demo\n",
        "    m = np.random.uniform(0.5, 0.9)\n",
        "    l, u = max(0, m-0.1), min(1, m+0.1)\n",
        "    company_a_fuzzy.set_performance_score(leaf.id, TFN(l, m, u))\n",
        "\n",
        "company_b_fuzzy = Alternative(\"Company B\")\n",
        "for leaf in leaf_nodes:\n",
        "    m = np.random.uniform(0.4, 0.8)\n",
        "    l, u = max(0, m-0.1), min(1, m+0.1)\n",
        "    company_b_fuzzy.set_performance_score(leaf.id, TFN(l, m, u))\n",
        "\n",
        "fuzzy_model.add_alternative(company_a_fuzzy)\n",
        "fuzzy_model.add_alternative(company_b_fuzzy)"
      ],
      "metadata": {
        "id": "uujWNowKVdf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Validating the Model Setup"
      ],
      "metadata": {
        "id": "xYRK2_DkViOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_results = Validation.run_all_validations(fuzzy_model)\n",
        "\n",
        "# Check if there are any errors\n",
        "has_errors = any(len(error_list) > 0 for error_list in validation_results.values())\n",
        "\n",
        "if has_errors:\n",
        "    print(\"VALIDATION FAILED. Please fix the following issues:\")\n",
        "    for category, errors in validation_results.items():\n",
        "        if errors:\n",
        "            print(f\"\\n  Category: {category}\")\n",
        "            for error in errors:\n",
        "                print(f\"    - {error}\")"
      ],
      "metadata": {
        "id": "wKqna3tKVHUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Run the Final Score Calculation"
      ],
      "metadata": {
        "id": "OrlCDD6OVxTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_model.calculate_weights()\n",
        "fuzzy_model.calculate_alternative_scores()\n",
        "\n",
        "\n",
        "print(\"\\n\\n--- FUZZY AHP FINAL RESULTS ---\")\n",
        "# The overall scores are TFNs, so we must defuzzify to rank.\n",
        "print(\"Overall Fuzzy Scores:\")\n",
        "for alt in fuzzy_model.alternatives:\n",
        "    print(f\"  - {alt.name}: {alt.overall_score}\")\n",
        "\n",
        "print(\"\\nFinal Crisp Rankings (using 'centroid' defuzzification):\")\n",
        "fuzzy_rankings = fuzzy_model.get_rankings(defuzzify_method='centroid')\n",
        "for i, (name, score) in enumerate(fuzzy_rankings):\n",
        "    print(f\"{i+1}. {name}: {score:.4f}\")\n",
        "\n",
        "fuzzy_model.display()"
      ],
      "metadata": {
        "id": "Us-0FhePc_RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Generating Full Analysis Report"
      ],
      "metadata": {
        "id": "oNUpVGkNgG-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_string = fuzzy_model.full_report()\n",
        "print(report_string)"
      ],
      "metadata": {
        "id": "yvLEUoJFfgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Exporting Full Analysis Report to Google Sheets"
      ],
      "metadata": {
        "id": "gKqphwOzgNEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, make sure to install the necessary libraries in a Colab cell\n",
        "!pip install gspread gspread-dataframe google-auth pandas openpyxl"
      ],
      "metadata": {
        "id": "8ho4fWRjgf0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "spreadsheet_id is required:\n",
        "1. Go to Google Sheets. here: [sheets.google.com](sheets.google.com)  \n",
        "2. Create a new sheet.\n",
        "3. Copy the ID from the URL.\n",
        "4. Paste it into the code.\n",
        "\n",
        "After giving permission to write in the given spreadsheet, following will be printed (spreadsheet id is an example, please provide spreadsheet id below)\n",
        "\n",
        "Starting Google Sheets export...\n",
        "  - Authenticating with Google...\n",
        "  - Authentication successful.\n",
        "  - Successfully opened existing spreadsheet: 'myFAHanalysis'\n",
        "    - Uploaded report for 'Goal' to sheet 'Goal'.\n",
        "    - Uploaded report for 'C1' to sheet 'C1'.\n",
        "    - Uploaded report for 'C2' to sheet 'C2'.\n",
        "    - Uploaded report for 'C3' to sheet 'C3'.\n",
        "    - Uploaded report for 'C4' to sheet 'C4'.\n",
        "\n",
        "âœ… Google Sheets report complete!\n",
        "   URL: https://docs.google.com/spreadsheets/d/PleaSe3nterY0ur-Spr34dshEetID"
      ],
      "metadata": {
        "id": "__aH-Mwfl_06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spreadsheet_id = \"PleaSe3nterY0ur-Spr34dshEetID\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "SN_8RhDyl_Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_model.export_report(target=\"myFAHanalysis\", spreadsheet_id=spreadsheet_id, output_format='gsheet')"
      ],
      "metadata": {
        "id": "Z0hIJTKdjF0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2: CLASSIC AHP DEMONSTRATION**\n",
        "\n",
        "First, comparison with pyDecision to be sure results are same."
      ],
      "metadata": {
        "id": "8cmG2W4hEQOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Valdecy/pyDecision.git\n",
        "import sys\n",
        "sys.path.insert(0, '/content/pyDecision')\n",
        "\n",
        "import numpy as np\n",
        "from pyDecision.algorithm import ahp_method\n",
        "\n",
        "# Parameters\n",
        "weight_derivation = 'max_eigen' # 'mean'; 'geometric' or 'max_eigen'\n",
        "\n",
        "# Dataset\n",
        "dataset = np.array([\n",
        "  #g1     g2     g3     g4     g5     g6     g7\n",
        "  [1  ,   1/3,   1/5,   1  ,   1/4,   1/2,   3  ],   #g1\n",
        "  [3  ,   1  ,   1/2,   2  ,   1/3,   3  ,   3  ],   #g2\n",
        "  [5  ,   2  ,   1  ,   4  ,   5  ,   6  ,   5  ],   #g3\n",
        "  [1  ,   1/2,   1/4,   1  ,   1/4,   1  ,   2  ],   #g4\n",
        "  [4  ,   3  ,   1/5,   4  ,   1  ,   3  ,   2  ],   #g5\n",
        "  [2  ,   1/3,   1/6,   1  ,   1/3,   1  ,   1/3],   #g6\n",
        "  [1/3,   1/3,   1/5,   1/2,   1/2,   3  ,   1  ]    #g7\n",
        "])\n",
        "\n",
        "# Call AHP Function\n",
        "weights, rc = ahp_method(dataset, wd = weight_derivation)\n",
        "\n",
        "# Weigths\n",
        "for i in range(0, weights.shape[0]):\n",
        "  print('w(g'+str(i+1)+'): ', round(weights[i], 3))\n",
        "\n",
        "# Consistency Ratio\n",
        "print('RC: ' + str(round(rc, 2)))\n",
        "if (rc > 0.10):\n",
        "  print('The solution is inconsistent, the pairwise comparisons must be reviewed')\n",
        "else:\n",
        "  print('The solution is consistent')"
      ],
      "metadata": {
        "id": "rCScfp8zB3NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mberkancetin/fuzzy-ahp-color.git\n",
        "import sys\n",
        "sys.path.insert(0, '/content/fuzzy-ahp-color')\n",
        "\n",
        "from multiAHPy.model import Node, Alternative, Hierarchy\n",
        "from multiAHPy.types import TFN, TrFN, Crisp, GFN, NumericType, Number\n",
        "from multiAHPy.validation import Validation\n",
        "from multiAHPy.consistency import Consistency\n",
        "\n",
        "goal = Node(\"Goal\", \"Corporate Local Responsibility (COLOR) Score\")\n",
        "criteria_nodes = {\n",
        "    \"C1\": Node(\"C1\", \"Generosity & Benevolence\"),\n",
        "    \"C2\": Node(\"C2\", \"Societal Demand\"),\n",
        "    \"C3\": Node(\"C3\", \"Compliance\"),\n",
        "    \"C4\": Node(\"C4\", \"Stakeholder Involvement\"),\n",
        "    \"C5\": Node(\"C5\", \"Environment\"),\n",
        "    \"C6\": Node(\"C6\", \"Social\"),\n",
        "    \"C7\": Node(\"C7\", \"Governance\")\n",
        "}\n",
        "for c_node in criteria_nodes.values():\n",
        "    goal.add_child(c_node)\n",
        "\n",
        "crisp_model = Hierarchy[Crisp](root_node=goal, number_type=Crisp)\n",
        "\n",
        "crisp_model.set_comparison_matrix(\"Goal\", dataset)\n",
        "crisp_model.calculate_weights(method=\"eigenvector\")"
      ],
      "metadata": {
        "id": "S_OV_0JTCe0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crisp_model.display()"
      ],
      "metadata": {
        "id": "ir8liTqJLU11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Step: Add Alternatives with CRISP Performance Scores"
      ],
      "metadata": {
        "id": "yoDidI5iEenS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "company_a_crisp = Alternative(\"Company A\")\n",
        "leaf_nodes_crisp = crisp_model.root.get_all_leaf_nodes()\n",
        "for leaf in leaf_nodes_crisp:\n",
        "    # Scores are simple floats wrapped in the Crisp class\n",
        "    company_a_crisp.set_performance_score(leaf.id, Crisp(np.random.uniform(0.5, 0.9)))\n",
        "\n",
        "company_b_crisp = Alternative(\"Company B\")\n",
        "for leaf in leaf_nodes_crisp:\n",
        "    company_b_crisp.set_performance_score(leaf.id, Crisp(np.random.uniform(0.4, 0.8)))\n",
        "\n",
        "crisp_model.add_alternative(company_a_crisp)\n",
        "crisp_model.add_alternative(company_b_crisp)\n",
        "print(\"Alternatives with Crisp scores added.\")\n",
        "\n",
        "# --- Calculate Final Crisp Scores and Rank ---\n",
        "crisp_model.calculate_alternative_scores()\n",
        "\n",
        "print(\"\\n\\n--- CLASSIC AHP FINAL RESULTS ---\")\n",
        "# The overall scores are already crisp, but get_rankings still works.\n",
        "print(\"Overall Crisp Scores:\")\n",
        "for alt in crisp_model.alternatives:\n",
        "    print(f\"  - {alt.name}: {alt.overall_score}\")\n",
        "\n",
        "print(\"\\nFinal Crisp Rankings:\")\n",
        "crisp_rankings = crisp_model.get_rankings()\n",
        "for i, (name, score) in enumerate(crisp_rankings):\n",
        "    print(f\"{i+1}. {name}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "HMVzw60qdrWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crisp_model.display()"
      ],
      "metadata": {
        "id": "05UXqmzlEp-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crisp_model.summary(\"Company A\")"
      ],
      "metadata": {
        "id": "bNfmA7qLEt59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crisp_model.summary(\"Company B\")"
      ],
      "metadata": {
        "id": "IPoIzJmGFVq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfeASlQ-Fey7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}